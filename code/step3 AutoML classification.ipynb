{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metrics\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from sklearn.metrics import cohen_kappa_score, matthews_corrcoef\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "\n",
    "\n",
    "def socre(y_true, y_pred, y_proba, k):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
    "    # fpr, tpr, thresholds = roc_curve(y_true, y_pred, pos_label=2)\n",
    "    \n",
    "    score_roc_auc = roc_auc_score(y_true, y_proba)\n",
    "    score_accuracye = accuracy_score(y_true, y_pred)\n",
    "    score_precision = precision_score(y_true, y_pred)\n",
    "    score_f1 = f1_score(y_true, y_pred)\n",
    "    score_recall = recall_score(y_true, y_pred)\n",
    "    g_mean = np.sqrt((tn/(tn+fp)) * score_recall)   # Specificity * Sensitivity \n",
    "    score_kappa = cohen_kappa_score(y_true, y_pred)\n",
    "    score_mcc = matthews_corrcoef(y_true, y_pred)\n",
    "\n",
    "    print(f\"tn: {tn}, fp: {fp}, fn: {fn}, tp: {tp}\")\n",
    "    print(f'roc_auc_score : {round(score_roc_auc, k)}')\n",
    "    print(f'accuracy_score : {round(score_accuracye, k)}')\n",
    "    print(f'precision_score : {round(score_precision, k)}')\n",
    "    print(f'f1_score : {round(score_f1, k)}')\n",
    "    print(f'recall_score : {round(score_recall, k)}')\n",
    "    print(f'cohen_kappa_score : {round(score_kappa, k)}')\n",
    "    print(f'matthews_corrcoef : {round(score_mcc, k)}')\n",
    "    print(f'G-mean: {round(g_mean, 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "\n",
    "presets = ['best_quality']\n",
    "\n",
    "predictor = TabularPredictor(label=label1,\n",
    "                             path=save_path,\n",
    "                             eval_metric='roc_auc')\n",
    "hyperparameters = {\n",
    "                    'GBM': [\n",
    "                         {'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}},\n",
    "                         # {},\n",
    "                         # 'GBMLarge',\n",
    "                    ],\n",
    "\n",
    "                    'CAT': {},\n",
    "\n",
    "                    'XGB': {},\n",
    "\n",
    "                    # 'FASTAI': {},\n",
    "\n",
    "                    'RF': [\n",
    "                         {'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}},\n",
    "                         # {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}},\n",
    "                         # {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression']}},\n",
    "                    ],\n",
    "\n",
    "                    'XT': [\n",
    "                          {'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}},\n",
    "                    #     {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}},\n",
    "                    #     {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression']}},\n",
    "                    ],\n",
    "                    \n",
    "                    # 'KNN': [\n",
    "                    #      {'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}},\n",
    "                    #     {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}},\n",
    "                    # ],\n",
    "                }\n",
    "\n",
    "# Ten-fold cross validation, multi-layer stacking\n",
    "predictor.fit(train_data=train_data,\n",
    "             #ag_args_fit={'num_gpus': 1},  # 调用GPU训练\n",
    "             # tuning_data=val_data,\n",
    "             time_limit=3000,\n",
    "             presets=presets,\n",
    "             # auto_stack=True,\n",
    "             num_bag_sets=1,\n",
    "             # use_bag_holdout=True,\n",
    "             # holdout_frac = 0.3,\n",
    "             num_stack_levels=1,\n",
    "             num_bag_folds=10,\n",
    "             hyperparameters=hyperparameters,\n",
    "             )\n",
    "\n",
    "# Outputs the visual stack integration architecture of the model trained by fit().\n",
    "predictor.plot_ensemble_model()\n",
    "\n",
    "# Test validation cohort\n",
    "result = predictor.leaderboard(val_data, silent=True)\n",
    "result.to_csv(os.path.join(save_path, \"result.csv\"), index=False)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train set\n",
    "\n",
    "model_name = 'WeightedEnsemble_L2'\n",
    "\n",
    "pred_train  = predictor.get_oof_pred(model=model_name)\n",
    "pred_train_df  = pd.DataFrame(pred_train, columns=['pred_smote'])\n",
    "proba_train_df = predictor.get_oof_pred_proba(model=model_name)\n",
    "proba_train_df.columns = ['proba_smote_0', 'proba_smote_1']\n",
    "\n",
    "res_train = pd.concat([train_data, pred_train_df, proba_train_df, train_name], axis=1)\n",
    "res_train = res_train.iloc[0:971, :]\n",
    "res_train.to_csv(os.path.join(save_path, 'train_pred.csv'), index=False, encoding='utf')\n",
    "print(res_train.shape)\n",
    "res_train.head()\n",
    "\n",
    "print('Train: \\n')\n",
    "socre(res_train['label1'], \n",
    "      res_train['pred_smote'], \n",
    "      res_train['proba_smote_1'], \n",
    "      k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation set\n",
    "\n",
    "pred_val = predictor.predict(data=val_data, \n",
    "                             model=model_name)\n",
    "proba_val_df = predictor.predict_proba(data=val_data,\n",
    "                                       model=model_name)\n",
    "proba_val_df.columns = ['proba_smote_0', 'proba_smote_1']\n",
    "pred_val_df  = pd.DataFrame(pred_val)\n",
    "pred_val_df.columns=['pred_smote']\n",
    "\n",
    "res_val = pd.concat([val_data, pred_val_df, proba_val_df, val_name], axis=1)\n",
    "res_val.to_csv(os.path.join(save_path, 'val_pred.csv'), \n",
    "               index=False, \n",
    "               encoding='utf')\n",
    "\n",
    "print(res_val.shape)\n",
    "res_val.head()\n",
    "\n",
    "print('Validation: \\n')\n",
    "socre(res_val['label1'], \n",
    "      res_val['pred_smote'], \n",
    "      res_val['proba_smote_1'], \n",
    "      k=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogluon_070_cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
